{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content table:\n",
    "1. [Dependencies](#dependencies)\n",
    "2. [Size analysis](#size-analysis)\n",
    "3. [Analysis of overhanging trees](#analysis-of-overhanging-trees)\n",
    "4. [Non-matching samples](#non-matching-samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import normalize\n",
    "import rasterio\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "df_samples_meta = pd.read_csv(\"../data/test/dataset/samples_metadata.csv\", sep=';')\n",
    "print(len(df_samples_meta))\n",
    "print(df_samples_meta.columns)\n",
    "# categories of samples\n",
    "categories = {\n",
    "'b' : ['bare', 0],\n",
    "'e' : ['extensive', 1],\n",
    "'i' : ['intensive', 2],\n",
    "'l' : ['lawn', 3],\n",
    "'s' : ['spontaneous', 4],\n",
    "'t' : ['terraces', 5],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram general of #samples per size\n",
    "fig = plt.figure()\n",
    "num_bins = 20\n",
    "bins = ()\n",
    "histo = plt.hist(np.log(df_samples_meta.area), log=False, bins=num_bins)\n",
    "lst_xticks = np.exp(histo[1])\n",
    "plt.xticks(histo[1], labels=np.exp(histo[1]).astype(int),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram per class of #samples per size\n",
    "fig, axs = plt.subplots(2,3, figsize=(10,6),sharex= True)\n",
    "for idx, cat in enumerate(categories.items()):\n",
    "    ax = axs[idx // 3, idx % 3]\n",
    "    ax.set_title(cat[1][0])\n",
    "    ax.hist(np.log(df_samples_meta[df_samples_meta['class'] == cat[0]].area), log=False, bins=num_bins)\n",
    "    ax.set_xticks(histo[1][::2], labels=np.exp(histo[1][::2]).astype(int),rotation=90)\n",
    "# add a big axes, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "plt.ylabel('count [-]')\n",
    "plt.xlabel('area [$m2$]', labelpad=30)\n",
    "plt.suptitle(\"Histogram of the area per category\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../results/data_analysis/size_histo_per_cat.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot per class per class of #samples per size\n",
    "lst_ticks_labels = [x[0] for x in categories.values()]\n",
    "lst_ticks_labels.insert(0,\"\")\n",
    "max_val = df_samples_meta.area.max()\n",
    "fig = plt.figure()\n",
    "plt.boxplot([np.log(df_samples_meta[df_samples_meta['class'] == cat[0]].area)\n",
    "             for cat in categories.items()])\n",
    "plt.xticks(ticks=range(len(categories)+1), labels=lst_ticks_labels)\n",
    "plt.yticks(ticks=np.arange(0, np.log(max_val), np.log(max_val)/5),\n",
    "            labels=np.exp(np.arange(0, np.log(max_val), np.log(max_val)/5)).astype(int))\n",
    "plt.title('Boxplot of the area for each category')\n",
    "plt.ylabel(\"area [$m^2$]\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../results/data_analysis/size_boxplot_per_cat.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repartition of size of mislabeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "with open(\"../results/trainings/MSPP_num_epoch_50_290924/logs/samp_logs.pickle\",'rb') as file:\n",
    "    samp_logs = pickle.load(file)\n",
    "\n",
    "best_epoch = 47\n",
    "df_samp_logs_epoch = pd.DataFrame(samp_logs[best_epoch])\n",
    "df_mislabeled = df_samp_logs_epoch[df_samp_logs_epoch.target != df_samp_logs_epoch.pred]\n",
    "\n",
    "df_samp_logs_epoch_wo_rot = df_samp_logs_epoch[~df_samp_logs_epoch.egid.str.contains('_')]\n",
    "\n",
    "df_mislabeled.to_csv('../test/mislabeled.csv', sep=';', index=False)\n",
    "df_mislabeled = df_mislabeled[~df_mislabeled.egid.str.contains('_')]\n",
    "\n",
    "df_mislabeled.to_csv('../test/mislabeled_raw.csv', sep=';', index=False)\n",
    "\n",
    "df_samples_meta.EGID = df_samples_meta.EGID.astype(int)\n",
    "df_mislabeled.egid = df_mislabeled.egid.astype(int)\n",
    "df_samp_logs_epoch_wo_rot.egid = df_samp_logs_epoch_wo_rot.egid.astype(int)\n",
    "areas_all = df_samples_meta[df_samples_meta.EGID.isin(df_samp_logs_epoch_wo_rot.egid.values.astype(int))][['EGID', 'area']].rename(str.lower, axis='columns')\n",
    "areas_mislabeled = df_samples_meta[df_samples_meta.EGID.isin(df_mislabeled.egid.values.astype(int))][['EGID', 'area']].rename(str.lower, axis='columns')\n",
    "\n",
    "df_mislabeled.set_index('egid', inplace=True)\n",
    "df_samp_logs_epoch_wo_rot.set_index('egid', inplace=True)\n",
    "areas_mislabeled.set_index('egid', inplace=True)\n",
    "areas_all.set_index('egid',inplace=True)\n",
    "\n",
    "df_mislabeled = df_mislabeled.join(areas_mislabeled, how='inner')\n",
    "df_samp_logs_epoch_wo_rot = df_samp_logs_epoch_wo_rot.join(areas_all, how='inner')\n",
    "\n",
    "print(f\"Number of raw samples (without rotation) : {len(df_samp_logs_epoch_wo_rot)}\")\n",
    "print(f\"Number of misclassified raw samples (without rotation) : {len(df_mislabeled)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram general of #samples per size\n",
    "fig = plt.figure()\n",
    "num_bins = 20\n",
    "bins = ()\n",
    "histo = plt.hist(np.log(df_mislabeled.area), log=False, bins=num_bins)\n",
    "lst_xticks = np.exp(histo[1])\n",
    "plt.xticks(histo[1], labels=np.exp(histo[1]).astype(int),rotation=90)\n",
    "plt.ylabel('count [-]')\n",
    "plt.xlabel('area [$m2$]', labelpad=30)\n",
    "plt.suptitle(\"Histogram of the size for mislabeled samples.\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../results/data_analysis/size_histo_misclassified.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics\n",
    "\n",
    "# test correlation\n",
    "df_samp_logs_epoch_wo_rot.columns\n",
    "df_matching = df_samp_logs_epoch_wo_rot.pred == df_samp_logs_epoch_wo_rot.target\n",
    "df_corr_area_match = df_samp_logs_epoch_wo_rot.assign(match=df_matching.values)\n",
    "print(f\"\\nThe correlation between the area and the matching results is : {round(df_corr_area_match.area.corr(df_corr_area_match.match),3)}\")\n",
    "\n",
    "# box plots\n",
    "fig = plt.figure()\n",
    "max_val = df_samp_logs_epoch_wo_rot.area.max()\n",
    "plt.boxplot([np.log(x) for x in [df_samp_logs_epoch_wo_rot.area, df_mislabeled.area]])\n",
    "plt.xticks(ticks=[1,2], labels=[\"dataset\", 'misclassified'])\n",
    "plt.yticks(ticks = np.arange(0, np.log(max_val), np.log(max_val)/5),\n",
    "           labels=np.exp(np.arange(0, np.log(max_val), np.log(max_val)/5)).astype(int))\n",
    "plt.title('Boxplot of the area for dataset and misclassified ($\\\\rho =-0.087$)')\n",
    "plt.ylabel(\"area [$m^2$]\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../results/data_analysis/size_boxplot_full_vs_mis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of overhanging trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_overhanging = '../data/sources/gt_MNC_filtered.gpkg'\n",
    "src_original = '../data/sources/gt_tot.gpkg'\n",
    "src_rasters = \"../data/sources/scratch_dataset\"\n",
    "original_roofs = gpd.read_file(src_original).to_crs(2056)\n",
    "overhanging_roofs = gpd.read_file(src_overhanging).to_crs(2056)\n",
    "print(f\"represented classes : {overhanging_roofs['class'].unique()}\")\n",
    "print(f\"columns of overhanging: {overhanging_roofs.columns}\")\n",
    "print(f\"columns of original: {original_roofs.columns}\")\n",
    "print(f\"Number of samples: {len(overhanging_roofs)}\")\n",
    "print(f\"Difference with original : {len(original_roofs) - len(overhanging_roofs)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of class of removed samples\n",
    "removed_samples = original_roofs.merge(overhanging_roofs, how='left', on=['EGID', 'class'], indicator=True)\n",
    "removed_samples = removed_samples[removed_samples['_merge'] == 'left_only'].drop(['_merge'], axis=1).reset_index(drop=True)\n",
    "print(f\"Number of samples : {len(removed_samples)}\")\n",
    "print(\"Removed samples in classes:\")\n",
    "print(removed_samples[['EGID','class']].groupby('class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering bares on NDVI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_samp_gen(arr_input):\n",
    "    R = arr_input[1,:,:].astype(float)\n",
    "    NIR = arr_input[0,:,:].astype(float)\n",
    "    ndvi = np.divide(NIR - R, NIR + R, out=np.zeros(R.shape, dtype=float), where= NIR + R != 0)\n",
    "    ndvi = ndvi.reshape((1,ndvi.shape[0], ndvi.shape[1]))\n",
    "    return ndvi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rasters\n",
    "raster_list = []\n",
    "for r, d, f in os.walk(src_rasters):\n",
    "    for file in f:\n",
    "        if file.endswith('.tif'):\n",
    "            file_src = r + '/' + file\n",
    "            file_src = file_src.replace('\\\\','/')\n",
    "            raster_list.append(rasterio.open(file_src))\n",
    "\n",
    "list_egid_to_remove = []\n",
    "overlapping_roofs = []\n",
    "nonmatching_roofs = []\n",
    "for roof in tqdm(overhanging_roofs[overhanging_roofs['class'] == 'b'].itertuples(index=True), total=len(overhanging_roofs[overhanging_roofs['class'] == 'b']), desc=\"Clipping\"):\n",
    "    geom = roof.geometry\n",
    "    cat = roof[5]\n",
    "    egid = str(int(roof.EGID))\n",
    "    \n",
    "    # loop over the rasters to find the one matching\n",
    "    matching_rasters = []\n",
    "    matching_images = []\n",
    "    sample_formats = \"\"\n",
    "    for raster in raster_list:\n",
    "        # catch the error when polygon doesn't match raster and just continue to next raster\n",
    "        try:\n",
    "            out_image, out_transform = mask(raster, [geom], crop=True)\n",
    "            sample_formats = out_image.dtype\n",
    "        except ValueError:\n",
    "            continue\n",
    "        else:\n",
    "            if np.max(out_image) == 0:  # test if image is not full black\n",
    "                continue\n",
    "            matching_rasters.append(raster)\n",
    "            matching_images.append((out_image, out_transform))\n",
    "\n",
    "    # test if polygon match with one and only one raster:    \n",
    "    if len(matching_rasters) == 0:\n",
    "        nonmatching_roofs.append(egid)\n",
    "        continue\n",
    "    else:\n",
    "        img_size_max = np.sum(matching_images[0][0].shape)\n",
    "        for img, transf in matching_images:\n",
    "            if np.sum(img.shape) > img_size_max:\n",
    "                img_size_max = np.sum(img.shape)\n",
    "                out_image = img\n",
    "                out_transform = transf\n",
    "    ndvi_canal = ndvi_samp_gen(out_image)\n",
    "    out_image = np.concatenate([out_image, ndvi_canal])\n",
    "\n",
    "    if cat == 'b' and np.mean(ndvi_canal, where=ndvi_canal!=0.0) > 0.05:\n",
    "        list_egid_to_remove.append(egid)\n",
    "\n",
    "print(f\"Number of 'bare' samples to remove based on NDVI > 0.05 : {len(list_egid_to_remove)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_egid_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_test = []\n",
    "lst_test.append(np.random.rand(3,2,2))\n",
    "lst_test.append(np.random.rand(3,3,3))\n",
    "lst_test.append(np.random.rand(3,2,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-matching samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "samples_src = \"./nonmatchingsamples.csv\"\n",
    "roofs_src = \"../data/sources/gt_MNC_filtered.gpkg\"\n",
    "dataset = \"../data/sources/tlm_dataset\"\n",
    "\n",
    "lst_samples = pd.read_csv(samples_src, sep=';').columns\n",
    "lst_samples = [samp.replace(\"'\",\"\") for samp in lst_samples]\n",
    "lst_samples = [int(samp.replace(\" \",\"\")) for samp in lst_samples]\n",
    "print(lst_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roofs = gpd.read_file(roofs_src)\n",
    "non_matching_roofs = roofs.loc[roofs.EGID.isin(lst_samples)]\n",
    "\n",
    "# save non_matching roofs infos \n",
    "non_matching_roofs[['EGID','class']].to_csv('../results/data_analysis/non_matching_roofs.csv', sep=';', index=None)\n",
    "raster_list = []\n",
    "\n",
    "for r, d, f in os.walk(dataset):\n",
    "    for file in f:\n",
    "        if file.endswith('.tif'):\n",
    "            file_src = r + '/' + file\n",
    "            file_src = file_src.replace('\\\\','/')\n",
    "            raster_list.append(rasterio.open(file_src))\n",
    "print(raster_list)\n",
    "for roof in non_matching_roofs.itertuples():\n",
    "    egid = roof.EGID\n",
    "    geom = roof.geometry\n",
    "    for raster in raster_list:\n",
    "        # catch the error when polygon doesn't match raster and just continue to next raster\n",
    "        try:\n",
    "            out_image, out_transform = mask(raster, [geom], crop=True)\n",
    "            sample_formats = out_image.dtype\n",
    "        except ValueError:\n",
    "            continue\n",
    "        else:\n",
    "            if roof[5] != 'b':\n",
    "                out_image = out_image/np.max(out_image)*255\n",
    "                fig = plt.figure()\n",
    "                plt.imshow(np.moveaxis(out_image[1::,...].astype(int),0,2))\n",
    "                plt.title(f\"{egid} - {roof[5]}\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(non_matching_roofs[['class','EGID']].groupby('class').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(non_matching_roofs.EGID.values)\n",
    "print(roofs.loc[roofs.EGID.isin(non_matching_roofs.EGID.values),:])\n",
    "\n",
    "matching_roofs = roofs.drop(roofs.loc[roofs.EGID.isin(non_matching_roofs.EGID.values),:].index, axis=0)\n",
    "print(len(roofs))\n",
    "print(len(non_matching_roofs))\n",
    "print(len(matching_roofs))\n",
    "\n",
    "matching_roofs.to_file('../data/sources/gt_matching_roofs.gpkg', driver='GPKG')\n",
    "non_matching_roofs.to_file('../data/sources/gt_non_matching_roofs.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
